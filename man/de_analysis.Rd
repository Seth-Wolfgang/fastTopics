% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/de_analysis.R
\name{de_analysis}
\alias{de_analysis}
\alias{de_clusters}
\title{Differential Expression Analysis using a Topic Model}
\usage{
de_analysis(
  fit,
  X,
  s = rowSums(X),
  pseudocount = 0.01,
  fit.method = c("scd", "em", "mu", "ccd", "glm"),
  lfc.stat = "vsnull",
  shrink.method = c("ash", "none"),
  numiter = 20,
  minval = 1e-10,
  tol = 1e-08,
  conf.level = 0.9,
  ns = 1000,
  rw = 0.3,
  eps = 1e-15,
  nc = 1,
  verbose = TRUE,
  ...
)

de_clusters(cluster, X, ...)
}
\arguments{
\item{fit}{An object of class \dQuote{poisson_nmf_fit} or
\dQuote{multinom_topic_model_fit}. If a Poisson NMF fit is provided
as input, the corresponding multinomial topic model fit is
automatically recovered using \code{\link{poisson2multinom}}.}

\item{X}{The n x m counts matrix. It can be a sparse matrix (class
\code{"dgCMatrix"}) or dense matrix (class \code{"matrix"}).}

\item{s}{A numeric vector of length n determining how the rates are
scaled in the Poisson model. See \dQuote{Details} for guidance on
the choice of \code{s}.}

\item{pseudocount}{Observations with this value are added to the
counts matrix to stabilize maximum-likelihood estimation.}

\item{fit.method}{Method used to fit the Poisson models.  Note that
\code{fit.method = "glm"} is the slowest method, and is mainly used
for testing.}

\item{lfc.stat}{Description of "lfc.stat" input argument goes here.}

\item{shrink.method}{Method used to stabilize the LFC estimates.
When \code{shrink.method = "ash"}, the "adaptive shrinkage" method
implemented in the ashr package is used. When \code{shrink.method =
"none"}, no stabilization is performed, and the \dQuote{raw} LFC
estimates are returned.}

\item{numiter}{Maximum number of iterations performed in fitting
the Poisson models. When \code{fit.method = "glm"}, this is passed
as argument \code{maxit} to the \code{glm} function.}

\item{minval}{A small, positive number. All topic proportions less
than this value and greater than \code{1-minval} are set to this
value.}

\item{tol}{Controls the convergence tolerance for fitting the
Poisson models. When \code{fit.method = "glm"}, this is passed as
argument \code{epsilon} to function \code{glm}.}

\item{conf.level}{Describe input argument "conf.level" here.}

\item{ns}{Describe input argument "ns" here.}

\item{rw}{Describe input argument "rw" here.}

\item{eps}{A small, non-negative number added to the terms inside
the logarithms to avoid computing logarithms of zero.}

\item{nc}{Number of threads used in the multithreaded computations.}

\item{verbose}{When \code{verbose = TRUE}, progress information is
printed to the console.}

\item{\dots}{Additional arguments passed to \code{de_analysis}.}

\item{cluster}{A factor, or vector that can be converted to a
factor such as an integer or character vector, giving an assignment
of samples (rows of \code{X}) to clusters. This could be, for
example, the "cluster" output from \code{\link[stats]{kmeans}}.}
}
\value{
The return value is a list of m x k matrices, where m is
  the number of columns in the counts matrix, and k is the number of
  topics (for \code{de_clusters}, m is the number of
  clusters), and an additional vector:

\item{colmeans}{A vector of length m containing the count averages
  (\code{colMeans(X)}).}

\item{F0}{Estimates of the Poisson model parameters \eqn{f_0}.}

\item{F1}{Estimates of the Poisson model parameters \eqn{f_1}.}

\item{beta}{LFC estimates \code{beta = log2(F1/F0)}.}

\item{se}{Standard errors of the Poisson glm parameters \eqn{b =
  f_1 - f_0}. }

\item{Z}{z-scores for the Poisson glm parameters \eqn{b = f_1 -
  f_0}.}

\item{pval}{-log10 two-tailed p-values computed from the
  z-scores. In some extreme cases the calculations may produce zero
  or negative standard errors, in which case the standard errors are
  set to \code{NA} and the z-scores and -log10 p-values are set to
  zero.}
}
\description{
Implements methods for analysis of differential count
analysis using a topic model. These methods are motivated by gene
expression studies, but could have other uses, such as identifying
\dQuote{key words} in topics derived from text documents. To
improve accuracy of the differential expression analysis, an
empirical Bayes method is used to \dQuote{stabilize} the
estimates. A special case of \dQuote{hard} topic assignments is
also implemented---that is, the topic proportions are all zeros
and ones---which involves greatly simplified (and faster)
calculations. Use \code{de_clusters} for this special case.
}
\details{
The methods are based on the following univariate
(\dQuote{single-count}) Poisson model: \deqn{x_i ~ Poisson(s_i
\lambda_i),} in which the Poisson rates are defined as
\deqn{\lambda_i = (1 - q_i) f_0 + q_i f_1,} and where the two
unknowns to be estimated are \eqn{f_0, f_1 > 0.} This model is
applied separately to each count (column of the counts matrix), and
to each topic k. The \eqn{q_i}'s are the topic probabilities for a
given topic. An EM algorithm is used to compute maximum-likelihood
estimates (MLEs) of the two unknowns.

The log-fold change (LFC) statistics are defined as the log-ratio
of the two Poisson rate parameters, \eqn{\beta = \log_2(f_1/f_0)}.
This statistic measures the increase (or decrease) in occurance in
one topic compared to all other topics. The use of the base-2
logarithm comes from the convention used in gene expression
studies.

When each \eqn{s_i} (specified by input argument \code{s}) is equal
the total count for sample i (this is the default setting in
\code{de_analysis}), the Poisson model will closely approximate a
binomial model of the count data, so that the Poisson model
parameters \eqn{f_0, f_1} represent binomial probabilities.  In
this case, \eqn{\beta} represents the LFC in \emph{relative}
occurrence. (This Poisson approximation to the binomial is most
accurate when the total counts \code{rowSums(X)} are large and
\eqn{f_0, f_1} are small.)

Other choices for \code{s} are possible, and implement different
normalization schemes for the counts, and different interpretations
of the LFC statistics. Setting \code{s} to all ones implements the
differential count analysis with no normalization, and \eqn{\beta}
represents the LFC in \emph{absolute} occurrence. This choice could
be appropriate in settings where the total count is well-controlled
across samples (rows of \code{X}).

When \code{fit.method = "glm"}, the LFC estimates and test
statistics are implemented by \code{\link[stats]{glm}} with
\code{formula = x ~ b0 + b - 1} and \code{family = poisson(link =
"identity")}, where the unknowns are defined as \eqn{b_0 = f_0} and
\eqn{b = f_1 - f_0}. The outputted z-scores are p-values are for
the \code{b} coefficient; that is, they are test statistics for the
test that \eqn{f_0} and \eqn{f_1} are not equal.

When \code{fit.method = "optim"} or \code{fit.method = "em"},
maximum-likelihood estimates are computed using
\code{\link[stats]{optim}} or using a fast EM algorithm, and test
statistics (standard errors, z-scores and p-values) are based on a
Laplace approximation to the likelihood at the MLE. These
calculations closely reproduce the test statistic calculations in
\code{\link[stats]{glm}}.

We recommend setting \code{shrink.method = "ash"}, which uses the
\dQuote{adaptive shrinkage} method (Stephens, 2016) to improve
accuracy of the LFC estimates. The improvement in accuracy is
greatest for genes with low expression, or when the sample size is
small (or both). We follow the settings used in \code{lfcShrink}
from the DESeq2 package, with \code{type = "ashr"}.
}
\references{
Stephens, M. (2016). False discovery rates: a new deal.
\emph{Biostatistics} \bold{18}(2), kxw041.
\url{https://doi.org/10.1093/biostatistics/kxw041}

Zhu, A., Ibrahim, J. G. and Love, M. I. (2019). Heavy-tailed prior
distributions for sequence count data: removing the noise and
preserving large differences. \emph{Bioinformatics} \bold{35}(12),
2084â€“2092.
}
